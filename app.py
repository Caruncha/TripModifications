# app.py
from __future__ import annotations
import json
import streamlit as st
import streamlit.components.v1 as components

from config import SCHEMA_VERSION
from caching import cache_views, resource_build_map_html

st.set_page_config(page_title="Analyse TripModifications + GTFS ‚Äî JSON/PB/Textproto + carte", layout="wide")
st.title("Analyse TripModifications (JSON/PB/Textproto) vs GTFS ‚Äî Carte Folium")
st.caption(
    "D√©tour (rouge), trac√© originel (vert, issu de shapes.txt), "
    "arr√™ts originels (blancs, avec d√©part en vert et terminus en rouge), "
    "arr√™ts de remplacement (rose, positionn√©s avec stop_lat/stop_lon si fournis). "
    "Segments **ajout√©s (turquoise)** et **annul√©s (violet)** s'affichent lorsque fournis. "
    "Polylines nettoy√©es, analyse et diagnostics pr√©‚Äëcalcul√©s et mis en cache. "
    "Carte HTML pr√©‚Äërendue et centr√©e strictement sur le d√©tour."
)

with st.sidebar:
    st.header("Donn√©es d‚Äôentr√©e")
    with st.form("inputs_form"):
        tripmods_file = st.file_uploader("TripModifications (JSON / PB / textproto)", type=["json", "pb", "pbf", "bin", "txt"], key="tripmods_up")
        gtfs_file = st.file_uploader("GTFS (.zip)", type=["zip"], key="gtfs_up")
        decode_mode = st.selectbox("D√©codage polylines", ["Auto (recommand√©)", "Pr√©cision 1e-5", "Pr√©cision 1e-6"], index=0, key="decode_sel")
        dump_first = st.checkbox("Afficher le 1er trip_mod normalis√©", value=False, key="dump_first_cb")
        submitted = st.form_submit_button("Analyser", type="primary")
decode_flag = {"Auto (recommand√©)": "auto", "Pr√©cision 1e-5": "p5", "Pr√©cision 1e-6": "p6"}[st.session_state.get("decode_sel", "Auto (recommand√©)")]

if submitted:
    if not tripmods_file or not gtfs_file:
        st.error("Merci de s√©lectionner **TripModifications** (JSON/PB/textproto) **et** **GTFS** (.zip).")
    else:
        tripmods_bytes = tripmods_file.getvalue()
        gtfs_bytes = gtfs_file.getvalue()
        res = cache_views(tripmods_bytes, gtfs_bytes, decode_flag, SCHEMA_VERSION)
        st.session_state["last_results"] = res
        st.session_state["last_params"] = dict(decode_flag=decode_flag, schema_version=SCHEMA_VERSION)
        st.success("Analyse termin√©e ‚úÖ")

# R√©cup√©ration des r√©sultats (et v√©rif de version)
res = st.session_state.get("last_results")
if res and res.get("schema_version") != SCHEMA_VERSION:
    res = None
    st.session_state.pop("last_results", None)

if not res:
    st.info("Charge un TripModifications (JSON / PB / textproto) puis un GTFS (.zip), choisis la pr√©cision de d√©codage, et clique **Analyser**.")
    st.caption("Astuce : si ta polyligne vient d‚Äôun JSON, elle doit √™tre ¬´ d√©s√©chapp√©e ¬ª (retrait des \\\\ et \\n).")
    st.stop()

feed_json = res["feed_json"]
reports_plain = res["reports"]; totals = res["totals"]; total_shapes = res["total_shapes"]
needed_trip_ids = res["needed_trip_ids"]; needed_stop_ids = res["needed_stop_ids"]
details_tables_by_entity = res["details_tables_by_entity"]
temp_stops_points_by_entity = res["temp_stops_points_by_entity"]
shape_for_plot_by_entity = res["shape_for_plot_by_entity"]
shapes_plain = res["shapes_plain"]
original_poly_by_entity = res["original_poly_by_entity"]
original_shape_id_by_entity = res["original_shape_id_by_entity"]
original_stop_points_by_entity = res["original_stop_points_by_entity"]
original_stop_ids_by_entity = res["original_stop_ids_by_entity"]
added_segments_by_entity = res["added_segments_by_entity"]
canceled_segments_by_entity = res["canceled_segments_by_entity"]
gtfs_kpi = res["gtfs_kpi"]

# KPIs
c1, c2, c3, c4, c5, c6, c7 = st.columns(7)
c1.metric("Entit√©s", totals["total_entities"])
c2.metric("trip_ids s√©lectionn√©s", totals["total_trip_ids"])
c3.metric("modifications", totals["total_modifications"])
c4.metric("trip_ids manquants", totals["missing_trip_ids"])
c5.metric("selectors non r√©solus", totals["invalid_selectors"])
c6.metric("repl. stops inconnus GTFS", totals["unknown_replacement_stops"])
c7.metric("Shapes dans le feed (RT)", total_shapes)

# Liste des trip_id manquants
if totals.get("missing_trip_ids", 0) > 0:
    missing = res.get("missing_trip_ids", [])
    if missing:
        with st.expander("üö´ Voir la liste des trip_id manquants (uniques)"):
            st.write(f"**{len(missing)}** trip_id absents du GTFS (uniques).")
            st.code("\n".join(missing), language="text")
            st.download_button("‚¨áÔ∏è T√©l√©charger la liste (TXT)", data="\n".join(missing),
                               file_name="trip_ids_manquants.txt", mime="text/plain")

st.info(f"Filtrage GTFS ‚Üí trips requis: {len(needed_trip_ids):,} ¬∑ stops requis: {len(needed_stop_ids):,} ¬∑ shapes RT disponibles: {total_shapes:,}")
st.success(f"GTFS filtr√© : **{gtfs_kpi['trips']:,} trips**, **{gtfs_kpi['stop_times']:,} stop_times**, **{gtfs_kpi['stops_present']:,} stops**")
st.success(f"TripModifications : **{len(reports_plain)} entit√©s**")

if st.session_state.get("dump_first_cb") and reports_plain:
    with st.expander("Aper√ßu du 1er trip_mod (normalis√©)"):
        st.json(reports_plain[0])
if feed_json is not None:
    with st.expander("Aper√ßu brut du feed JSON (apr√®s normalisation camel‚Üísnake)"):
        st.json(feed_json)

# Synth√®se par entit√©
table = [{
    "entity_id": r["entity_id"],
    "trip_ids (s√©lectionn√©s)": r["total_selected_trip_ids"],
    "modifications": r["modification_count"],
    "service_dates": ", ".join(r["service_dates"]),
    "repl_stops inconnus": ", ".join(r["replacement_stops_unknown_in_gtfs"]) if r["replacement_stops_unknown_in_gtfs"] else ""
} for r in reports_plain if r.get("modification_count", 0) > 0]
st.subheader("Synth√®se par entit√©")
st.dataframe(table, width="stretch", height=360)

# D√©tails par entit√©
st.subheader("D√©tails")
for r in reports_plain[:200]:
    ent_id = r["entity_id"]
    if r["modification_count"] <= 0:
        continue
    with st.expander(f"Entit√© {ent_id} ‚Äî {r['total_selected_trip_ids']} trips ‚Äî {r['modification_count']} modifications"):
        st.write("**Dates** :", ", ".join(r["service_dates"]) if r["service_dates"] else "‚Äî")
        st.write("**Replacement stops inconnus dans GTFS (peuvent √™tre temporaires)** :", ", ".join(r["replacement_stops_unknown_in_gtfs"]) if r["replacement_stops_unknown_in_gtfs"] else "‚Äî")

        rows = details_tables_by_entity.get(ent_id, [])
        st.dataframe(rows, width="stretch", height=260) if rows else st.info("Aucune ligne de diagnostic pour cette entit√©.")

        rt_shape_id_for_plot = shape_for_plot_by_entity.get(ent_id)
        orig_shape_id = original_shape_id_by_entity.get(ent_id)
        st.write(f"**Shape d√©tour (RT)** : {rt_shape_id_for_plot or '‚Äî'}")
        st.write(f"**Shape originel (GTFS shapes.txt)** : {orig_shape_id or '‚Äî'}")

        if rt_shape_id_for_plot:
            coords_list = shapes_plain.get(rt_shape_id_for_plot, [])
            poly = [(float(la), float(lo)) for la, lo in coords_list]
            if poly and len(poly) >= 2:
                poly_key = tuple((round(la, 6), round(lo, 6)) for la, lo in poly)
                tmp_pts = temp_stops_points_by_entity.get(ent_id, [])
                stops_key = tuple((round(p[0], 6), round(p[1], 6), str(p[2])) for p in tmp_pts)
                orig_list = original_poly_by_entity.get(ent_id, [])
                orig_poly = [(float(la), float(lo)) for la, lo in orig_list]
                original_poly_key = tuple((round(la, 6), round(lo, 6)) for la, lo in orig_poly) if orig_poly else tuple()
                orig_stop_pts = original_stop_points_by_entity.get(ent_id, [])
                orig_stops_key = tuple((round(p[0], 6), round(p[1], 6), str(p[2])) for p in orig_stop_pts)

                add_list = added_segments_by_entity.get(ent_id, [])
                can_list = canceled_segments_by_entity.get(ent_id, [])
                def _segkey(lst):
                    return tuple(
                        tuple((round(p[0], 6), round(p[1], 6)) for p in seg if isinstance(p, list) and len(p) == 2)
                        for seg in lst
                    )
                added_key = _segkey(add_list)
                canceled_key = _segkey(can_list)

                map_html = resource_build_map_html(
                    rt_shape_id_for_plot or "",
                    poly_key,
                    stops_key,
                    original_poly_key,
                    orig_stops_key,
                    orig_shape_id or "",
                    added_key,
                    canceled_key,
                    SCHEMA_VERSION
                )
                components.html(map_html, height=460, scrolling=False)
                if orig_stop_pts:
                    st.markdown("**Arr√™ts du trac√© originel (ordre `stop_times`) :**")
                    ids_list = original_stop_ids_by_entity.get(ent_id, [])
                    st.markdown("\n".join(f"{i+1}. `{sid}`" for i, sid in enumerate(ids_list)))
            else:
                st.info("Polyline (d√©tour) vide ou invalide pour cette entit√©.")
        else:
            st.info("Aucune polyline 'encoded_polyline' (d√©tour RT) disponible pour cette entit√©.")

# Export JSON
export_json = {
    "schema_version": SCHEMA_VERSION,
    "totals": totals,
    "total_shapes": total_shapes,
    "entities": reports_plain,
}
st.download_button("üì• T√©l√©charger le rapport JSON",
    data=json.dumps(export_json, ensure_ascii=False, indent=2),
    file_name="rapport_tripmods.json", mime="application/json"
)